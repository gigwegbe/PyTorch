{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = Variable(torch.Tensor([1.0]), requires_grad=True) # a random guess: random value, 1.0\n",
    "w = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model for the forward pass\n",
    "def forward(x):\n",
    "    return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,y): # d_loss / d_w\n",
    "    return  2 * x * ( x * w - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  1.0 2.0 tensor(-2.)\n",
      "\tgrad:  2.0 4.0 tensor(-9.8400)\n",
      "\tgrad:  3.0 6.0 tensor(-25.7088)\n",
      "progress: 0 tensor(6.9950)\n",
      "\tgrad:  1.0 2.0 tensor(-26.9578)\n",
      "\tgrad:  2.0 4.0 tensor(-29.7973)\n",
      "\tgrad:  3.0 6.0 tensor(-30.8226)\n",
      "progress: 1 tensor(0.0292)\n",
      "\tgrad:  1.0 2.0 tensor(-30.3201)\n",
      "\tgrad:  2.0 4.0 tensor(-25.8843)\n",
      "\tgrad:  3.0 6.0 tensor(-11.2448)\n",
      "progress: 2 tensor(5.9532)\n",
      "\tgrad:  1.0 2.0 tensor(-9.3933)\n",
      "\tgrad:  2.0 4.0 tensor(-1.2357)\n",
      "\tgrad:  3.0 6.0 tensor(17.3411)\n",
      "progress: 3 tensor(9.5861)\n",
      "\tgrad:  1.0 2.0 tensor(19.0584)\n",
      "\tgrad:  2.0 4.0 tensor(24.4028)\n",
      "\tgrad:  3.0 6.0 tensor(32.0352)\n",
      "progress: 4 tensor(1.6182)\n",
      "\tgrad:  1.0 2.0 tensor(32.2426)\n",
      "\tgrad:  2.0 4.0 tensor(30.4925)\n",
      "\tgrad:  3.0 6.0 tensor(21.0663)\n",
      "progress: 5 tensor(2.4682)\n",
      "\tgrad:  1.0 2.0 tensor(19.5976)\n",
      "\tgrad:  2.0 4.0 tensor(12.1551)\n",
      "\tgrad:  3.0 6.0 tensor(-6.7786)\n",
      "progress: 6 tensor(9.9579)\n",
      "\tgrad:  1.0 2.0 tensor(-8.7467)\n",
      "\tgrad:  2.0 4.0 tensor(-15.9197)\n",
      "\tgrad:  3.0 6.0 tensor(-29.1932)\n",
      "progress: 7 tensor(4.8941)\n",
      "\tgrad:  1.0 2.0 tensor(-30.0842)\n",
      "\tgrad:  2.0 4.0 tensor(-31.2414)\n",
      "\tgrad:  3.0 6.0 tensor(-28.2215)\n",
      "progress: 8 tensor(0.2533)\n",
      "\tgrad:  1.0 2.0 tensor(-27.3216)\n",
      "\tgrad:  2.0 4.0 tensor(-21.5360)\n",
      "\tgrad:  3.0 6.0 tensor(-4.6419)\n",
      "progress: 9 tensor(7.9280)\n",
      "\tgrad:  1.0 2.0 tensor(-2.6720)\n",
      "\tgrad:  2.0 4.0 tensor(5.4216)\n",
      "\tgrad:  3.0 6.0 tensor(22.6563)\n",
      "progress: 10 tensor(8.2509)\n",
      "\tgrad:  1.0 2.0 tensor(24.1181)\n",
      "\tgrad:  2.0 4.0 tensor(28.0360)\n",
      "\tgrad:  3.0 6.0 tensor(31.8048)\n",
      "progress: 11 tensor(0.3945)\n",
      "\tgrad:  1.0 2.0 tensor(31.5875)\n",
      "\tgrad:  2.0 4.0 tensor(28.1911)\n",
      "\tgrad:  3.0 6.0 tensor(15.4749)\n",
      "progress: 12 tensor(4.4917)\n",
      "\tgrad:  1.0 2.0 tensor(13.7525)\n",
      "\tgrad:  2.0 4.0 tensor(5.7626)\n",
      "\tgrad:  3.0 6.0 tensor(-13.2518)\n",
      "progress: 13 tensor(10.0430)\n",
      "\tgrad:  1.0 2.0 tensor(-15.0994)\n",
      "\tgrad:  2.0 4.0 tensor(-21.2822)\n",
      "\tgrad:  3.0 6.0 tensor(-31.3626)\n",
      "progress: 14 tensor(2.8226)\n",
      "\tgrad:  1.0 2.0 tensor(-31.8554)\n",
      "\tgrad:  2.0 4.0 tensor(-31.2781)\n",
      "\tgrad:  3.0 6.0 tensor(-24.3492)\n",
      "progress: 15 tensor(1.3336)\n",
      "\tgrad:  1.0 2.0 tensor(-23.0924)\n",
      "\tgrad:  2.0 4.0 tensor(-16.2175)\n",
      "\tgrad:  3.0 6.0 tensor(2.1700)\n",
      "progress: 16 tensor(9.3917)\n",
      "\tgrad:  1.0 2.0 tensor(4.1697)\n",
      "\tgrad:  2.0 4.0 tensor(11.8347)\n",
      "\tgrad:  3.0 6.0 tensor(26.9509)\n",
      "progress: 17 tensor(6.3472)\n",
      "\tgrad:  1.0 2.0 tensor(28.0914)\n",
      "\tgrad:  2.0 4.0 tensor(30.4063)\n",
      "\tgrad:  3.0 6.0 tensor(30.1417)\n",
      "progress: 18 tensor(0.0019)\n",
      "\tgrad:  1.0 2.0 tensor(29.5095)\n",
      "\tgrad:  2.0 4.0 tensor(24.6198)\n",
      "\tgrad:  3.0 6.0 tensor(9.1864)\n",
      "progress: 19 tensor(6.6164)\n",
      "\tgrad:  1.0 2.0 tensor(7.2878)\n",
      "\tgrad:  2.0 4.0 tensor(-0.8894)\n",
      "\tgrad:  3.0 6.0 tensor(-19.1280)\n",
      "progress: 20 tensor(9.2402)\n",
      "\tgrad:  1.0 2.0 tensor(-20.7720)\n",
      "\tgrad:  2.0 4.0 tensor(-25.6861)\n",
      "\tgrad:  3.0 6.0 tensor(-32.1192)\n",
      "progress: 21 tensor(1.1496)\n",
      "\tgrad:  1.0 2.0 tensor(-32.1916)\n",
      "\tgrad:  2.0 4.0 tensor(-29.9059)\n",
      "\tgrad:  3.0 6.0 tensor(-19.3801)\n",
      "progress: 22 tensor(3.0776)\n",
      "\tgrad:  1.0 2.0 tensor(-17.8229)\n",
      "\tgrad:  2.0 4.0 tensor(-10.1685)\n",
      "\tgrad:  3.0 6.0 tensor(8.8842)\n",
      "progress: 23 tensor(10.0835)\n",
      "\tgrad:  1.0 2.0 tensor(10.8235)\n",
      "\tgrad:  2.0 4.0 tensor(17.7148)\n",
      "\tgrad:  3.0 6.0 tensor(30.0315)\n",
      "progress: 24 tensor(4.2139)\n",
      "\tgrad:  1.0 2.0 tensor(30.7994)\n",
      "\tgrad:  2.0 4.0 tensor(31.4070)\n",
      "\tgrad:  3.0 6.0 tensor(27.1209)\n",
      "progress: 25 tensor(0.5103)\n",
      "\tgrad:  1.0 2.0 tensor(26.1022)\n",
      "\tgrad:  2.0 4.0 tensor(19.9394)\n",
      "\tgrad:  3.0 6.0 tensor(2.4841)\n",
      "progress: 26 tensor(8.4636)\n",
      "\tgrad:  1.0 2.0 tensor(0.4949)\n",
      "\tgrad:  2.0 4.0 tensor(-7.5013)\n",
      "\tgrad:  3.0 6.0 tensor(-24.1427)\n",
      "progress: 27 tensor(7.6926)\n",
      "\tgrad:  1.0 2.0 tensor(-25.5089)\n",
      "\tgrad:  2.0 4.0 tensor(-28.9329)\n",
      "\tgrad:  3.0 6.0 tensor(-31.4290)\n",
      "progress: 28 tensor(0.1731)\n",
      "\tgrad:  1.0 2.0 tensor(-31.0778)\n",
      "\tgrad:  2.0 4.0 tensor(-27.1867)\n",
      "\tgrad:  3.0 6.0 tensor(-13.5380)\n",
      "progress: 29 tensor(5.1746)\n",
      "\tgrad:  1.0 2.0 tensor(-11.7507)\n",
      "\tgrad:  2.0 4.0 tensor(-3.6615)\n",
      "\tgrad:  3.0 6.0 tensor(15.1982)\n",
      "progress: 30 tensor(9.8802)\n",
      "\tgrad:  1.0 2.0 tensor(16.9898)\n",
      "\tgrad:  2.0 4.0 tensor(22.7968)\n",
      "\tgrad:  3.0 6.0 tensor(31.7593)\n",
      "progress: 31 tensor(2.2313)\n",
      "\tgrad:  1.0 2.0 tensor(32.1199)\n",
      "\tgrad:  2.0 4.0 tensor(30.9929)\n",
      "\tgrad:  3.0 6.0 tensor(22.8784)\n",
      "progress: 32 tensor(1.8290)\n",
      "\tgrad:  1.0 2.0 tensor(21.5192)\n",
      "\tgrad:  2.0 4.0 tensor(14.3609)\n",
      "\tgrad:  3.0 6.0 tensor(-4.3301)\n",
      "progress: 33 tensor(9.7043)\n",
      "\tgrad:  1.0 2.0 tensor(-6.3203)\n",
      "\tgrad:  2.0 4.0 tensor(-13.7754)\n",
      "\tgrad:  3.0 6.0 tensor(-28.0698)\n",
      "progress: 34 tensor(5.6758)\n",
      "\tgrad:  1.0 2.0 tensor(-29.0967)\n",
      "\tgrad:  2.0 4.0 tensor(-30.8764)\n",
      "\tgrad:  3.0 6.0 tensor(-29.3231)\n",
      "progress: 35 tensor(0.0670)\n",
      "\tgrad:  1.0 2.0 tensor(-28.5641)\n",
      "\tgrad:  2.0 4.0 tensor(-23.2427)\n",
      "\tgrad:  3.0 6.0 tensor(-7.0860)\n",
      "progress: 36 tensor(7.2511)\n",
      "\tgrad:  1.0 2.0 tensor(-5.1491)\n",
      "\tgrad:  2.0 4.0 tensor(3.0105)\n",
      "\tgrad:  3.0 6.0 tensor(20.8276)\n",
      "progress: 37 tensor(8.8181)\n",
      "\tgrad:  1.0 2.0 tensor(22.3907)\n",
      "\tgrad:  2.0 4.0 tensor(26.8520)\n",
      "\tgrad:  3.0 6.0 tensor(32.0565)\n",
      "progress: 38 tensor(0.7524)\n",
      "\tgrad:  1.0 2.0 tensor(31.9936)\n",
      "\tgrad:  2.0 4.0 tensor(29.1827)\n",
      "\tgrad:  3.0 6.0 tensor(17.6053)\n",
      "progress: 39 tensor(3.7232)\n",
      "\tgrad:  1.0 2.0 tensor(15.9668)\n",
      "\tgrad:  2.0 4.0 tensor(8.1355)\n",
      "\tgrad:  3.0 6.0 tensor(-10.9493)\n",
      "progress: 40 tensor(10.1175)\n",
      "\tgrad:  1.0 2.0 tensor(-12.8508)\n",
      "\tgrad:  2.0 4.0 tensor(-19.4289)\n",
      "\tgrad:  3.0 6.0 tensor(-30.7325)\n",
      "progress: 41 tensor(3.5492)\n",
      "\tgrad:  1.0 2.0 tensor(-31.3738)\n",
      "\tgrad:  2.0 4.0 tensor(-31.4291)\n",
      "\tgrad:  3.0 6.0 tensor(-25.8963)\n",
      "progress: 42 tensor(0.8503)\n",
      "\tgrad:  1.0 2.0 tensor(-24.7636)\n",
      "\tgrad:  2.0 4.0 tensor(-18.2518)\n",
      "\tgrad:  3.0 6.0 tensor(-0.3149)\n",
      "progress: 43 tensor(8.9370)\n",
      "\tgrad:  1.0 2.0 tensor(1.6844)\n",
      "\tgrad:  2.0 4.0 tensor(9.5468)\n",
      "\tgrad:  3.0 6.0 tensor(25.5188)\n",
      "progress: 44 tensor(7.0862)\n",
      "\tgrad:  1.0 2.0 tensor(26.7831)\n",
      "\tgrad:  2.0 4.0 tensor(29.6976)\n",
      "\tgrad:  3.0 6.0 tensor(30.9097)\n",
      "progress: 45 tensor(0.0408)\n",
      "\tgrad:  1.0 2.0 tensor(30.4261)\n",
      "\tgrad:  2.0 4.0 tensor(26.0580)\n",
      "\tgrad:  3.0 6.0 tensor(11.5392)\n",
      "progress: 46 tensor(5.8554)\n",
      "\tgrad:  1.0 2.0 tensor(9.6952)\n",
      "\tgrad:  2.0 4.0 tensor(1.5437)\n",
      "\tgrad:  3.0 6.0 tensor(-17.0752)\n",
      "progress: 47 tensor(9.6295)\n",
      "\tgrad:  1.0 2.0 tensor(-18.8025)\n",
      "\tgrad:  2.0 4.0 tensor(-24.2073)\n",
      "\tgrad:  3.0 6.0 tensor(-32.0108)\n",
      "progress: 48 tensor(1.6915)\n",
      "\tgrad:  1.0 2.0 tensor(-32.2377)\n",
      "\tgrad:  2.0 4.0 tensor(-30.5661)\n",
      "\tgrad:  3.0 6.0 tensor(-21.3030)\n",
      "progress: 49 tensor(2.3835)\n",
      "\tgrad:  1.0 2.0 tensor(-19.8477)\n",
      "\tgrad:  2.0 4.0 tensor(-12.4387)\n",
      "\tgrad:  3.0 6.0 tensor(6.4704)\n",
      "progress: 50 tensor(9.9321)\n",
      "\tgrad:  1.0 2.0 tensor(8.4421)\n",
      "\tgrad:  2.0 4.0 tensor(15.6531)\n",
      "\tgrad:  3.0 6.0 tensor(29.0605)\n",
      "progress: 51 tensor(4.9932)\n",
      "\tgrad:  1.0 2.0 tensor(29.9690)\n",
      "\tgrad:  2.0 4.0 tensor(31.2054)\n",
      "\tgrad:  3.0 6.0 tensor(28.3705)\n",
      "progress: 52 tensor(0.2232)\n",
      "\tgrad:  1.0 2.0 tensor(27.4881)\n",
      "\tgrad:  2.0 4.0 tensor(21.7594)\n",
      "\tgrad:  3.0 6.0 tensor(4.9533)\n",
      "progress: 53 tensor(7.8458)\n",
      "\tgrad:  1.0 2.0 tensor(2.9868)\n",
      "\tgrad:  2.0 4.0 tensor(-5.1178)\n",
      "\tgrad:  3.0 6.0 tensor(-22.4320)\n",
      "progress: 54 tensor(8.3273)\n",
      "\tgrad:  1.0 2.0 tensor(-23.9071)\n",
      "\tgrad:  2.0 4.0 tensor(-27.8952)\n",
      "\tgrad:  3.0 6.0 tensor(-31.8472)\n",
      "progress: 55 tensor(0.4338)\n",
      "\tgrad:  1.0 2.0 tensor(-31.6494)\n",
      "\tgrad:  2.0 4.0 tensor(-28.3261)\n",
      "\tgrad:  3.0 6.0 tensor(-15.7500)\n",
      "progress: 56 tensor(4.3933)\n",
      "\tgrad:  1.0 2.0 tensor(-14.0377)\n",
      "\tgrad:  2.0 4.0 tensor(-6.0653)\n",
      "\tgrad:  3.0 6.0 tensor(12.9643)\n",
      "progress: 57 tensor(10.0591)\n",
      "\tgrad:  1.0 2.0 tensor(14.8194)\n",
      "\tgrad:  2.0 4.0 tensor(21.0543)\n",
      "\tgrad:  3.0 6.0 tensor(31.2931)\n",
      "progress: 58 tensor(2.9120)\n",
      "\tgrad:  1.0 2.0 tensor(31.8049)\n",
      "\tgrad:  2.0 4.0 tensor(31.3076)\n",
      "\tgrad:  3.0 6.0 tensor(24.5534)\n",
      "progress: 59 tensor(1.2672)\n",
      "\tgrad:  1.0 2.0 tensor(23.3118)\n",
      "\tgrad:  2.0 4.0 tensor(16.4807)\n",
      "\tgrad:  3.0 6.0 tensor(-1.8558)\n",
      "progress: 60 tensor(9.3397)\n",
      "\tgrad:  1.0 2.0 tensor(-3.8561)\n",
      "\tgrad:  2.0 4.0 tensor(-11.5487)\n",
      "\tgrad:  3.0 6.0 tensor(-26.7783)\n",
      "progress: 61 tensor(6.4428)\n",
      "\tgrad:  1.0 2.0 tensor(-27.9349)\n",
      "\tgrad:  2.0 4.0 tensor(-30.3266)\n",
      "\tgrad:  3.0 6.0 tensor(-30.2490)\n",
      "progress: 62 tensor(0.0002)\n",
      "\tgrad:  1.0 2.0 tensor(-29.6354)\n",
      "\tgrad:  2.0 4.0 tensor(-24.8102)\n",
      "\tgrad:  3.0 6.0 tensor(-9.4876)\n",
      "progress: 63 tensor(6.5217)\n",
      "\tgrad:  1.0 2.0 tensor(-7.5954)\n",
      "\tgrad:  2.0 4.0 tensor(0.5813)\n",
      "\tgrad:  3.0 6.0 tensor(18.8742)\n",
      "progress: 64 tensor(9.2953)\n",
      "\tgrad:  1.0 2.0 tensor(20.5292)\n",
      "\tgrad:  2.0 4.0 tensor(25.5071)\n",
      "\tgrad:  3.0 6.0 tensor(32.1161)\n",
      "progress: 65 tensor(1.2133)\n",
      "\tgrad:  1.0 2.0 tensor(32.2081)\n",
      "\tgrad:  2.0 4.0 tensor(29.9995)\n",
      "\tgrad:  3.0 6.0 tensor(19.6302)\n",
      "progress: 66 tensor(2.9867)\n",
      "\tgrad:  1.0 2.0 tensor(18.0855)\n",
      "\tgrad:  2.0 4.0 tensor(10.4596)\n",
      "\tgrad:  3.0 6.0 tensor(-8.5812)\n",
      "progress: 67 tensor(10.0710)\n",
      "\tgrad:  1.0 2.0 tensor(-10.5252)\n",
      "\tgrad:  2.0 4.0 tensor(-17.4593)\n",
      "\tgrad:  3.0 6.0 tensor(-29.9183)\n",
      "progress: 68 tensor(4.3119)\n",
      "\tgrad:  1.0 2.0 tensor(-30.7043)\n",
      "\tgrad:  2.0 4.0 tensor(-31.3918)\n",
      "\tgrad:  3.0 6.0 tensor(-27.2883)\n",
      "progress: 69 tensor(0.4678)\n",
      "\tgrad:  1.0 2.0 tensor(-26.2865)\n",
      "\tgrad:  2.0 4.0 tensor(-20.1767)\n",
      "\tgrad:  3.0 6.0 tensor(-2.7979)\n",
      "progress: 70 tensor(8.3896)\n",
      "\tgrad:  1.0 2.0 tensor(-0.8109)\n",
      "\tgrad:  2.0 4.0 tensor(7.2017)\n",
      "\tgrad:  3.0 6.0 tensor(23.9338)\n",
      "progress: 71 tensor(7.7768)\n",
      "\tgrad:  1.0 2.0 tensor(25.3143)\n",
      "\tgrad:  2.0 4.0 tensor(28.8109)\n",
      "\tgrad:  3.0 6.0 tensor(31.4924)\n",
      "progress: 72 tensor(0.1997)\n",
      "\tgrad:  1.0 2.0 tensor(31.1605)\n",
      "\tgrad:  2.0 4.0 tensor(27.3401)\n",
      "\tgrad:  3.0 6.0 tensor(13.8228)\n",
      "progress: 73 tensor(5.0754)\n",
      "\tgrad:  1.0 2.0 tensor(12.0445)\n",
      "\tgrad:  2.0 4.0 tensor(3.9674)\n",
      "\tgrad:  3.0 6.0 tensor(-14.9201)\n",
      "progress: 74 tensor(9.9094)\n",
      "\tgrad:  1.0 2.0 tensor(-16.7203)\n",
      "\tgrad:  2.0 4.0 tensor(-22.5835)\n",
      "\tgrad:  3.0 6.0 tensor(-31.7107)\n",
      "progress: 75 tensor(2.3140)\n",
      "\tgrad:  1.0 2.0 tensor(-32.0906)\n",
      "\tgrad:  2.0 4.0 tensor(-31.0431)\n",
      "\tgrad:  3.0 6.0 tensor(-23.0983)\n",
      "progress: 76 tensor(1.7533)\n",
      "\tgrad:  1.0 2.0 tensor(-21.7535)\n",
      "\tgrad:  2.0 4.0 tensor(-14.6344)\n",
      "\tgrad:  3.0 6.0 tensor(4.0179)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 77 tensor(9.6641)\n",
      "\tgrad:  1.0 2.0 tensor(6.0100)\n",
      "\tgrad:  2.0 4.0 tensor(13.4977)\n",
      "\tgrad:  3.0 6.0 tensor(27.9154)\n",
      "progress: 78 tensor(5.7742)\n",
      "\tgrad:  1.0 2.0 tensor(28.9591)\n",
      "\tgrad:  2.0 4.0 tensor(30.8170)\n",
      "\tgrad:  3.0 6.0 tensor(29.4502)\n",
      "progress: 79 tensor(0.0519)\n",
      "\tgrad:  1.0 2.0 tensor(28.7093)\n",
      "\tgrad:  2.0 4.0 tensor(23.4491)\n",
      "\tgrad:  3.0 6.0 tensor(7.3928)\n",
      "progress: 80 tensor(7.1613)\n",
      "\tgrad:  1.0 2.0 tensor(5.4609)\n",
      "\tgrad:  2.0 4.0 tensor(-2.7036)\n",
      "\tgrad:  3.0 6.0 tensor(-20.5869)\n",
      "progress: 81 tensor(8.8837)\n",
      "\tgrad:  1.0 2.0 tensor(-22.1622)\n",
      "\tgrad:  2.0 4.0 tensor(-26.6904)\n",
      "\tgrad:  3.0 6.0 tensor(-32.0746)\n",
      "progress: 82 tensor(0.8053)\n",
      "\tgrad:  1.0 2.0 tensor(-32.0314)\n",
      "\tgrad:  2.0 4.0 tensor(-29.2959)\n",
      "\tgrad:  3.0 6.0 tensor(-17.8678)\n",
      "progress: 83 tensor(3.6278)\n",
      "\tgrad:  1.0 2.0 tensor(-16.2406)\n",
      "\tgrad:  2.0 4.0 tensor(-8.4328)\n",
      "\tgrad:  3.0 6.0 tensor(10.6527)\n",
      "progress: 84 tensor(10.1183)\n",
      "\tgrad:  1.0 2.0 tensor(12.5603)\n",
      "\tgrad:  2.0 4.0 tensor(19.1857)\n",
      "\tgrad:  3.0 6.0 tensor(30.6395)\n",
      "progress: 85 tensor(3.6441)\n",
      "\tgrad:  1.0 2.0 tensor(31.2993)\n",
      "\tgrad:  2.0 4.0 tensor(31.4348)\n",
      "\tgrad:  3.0 6.0 tensor(26.0813)\n",
      "progress: 86 tensor(0.7961)\n",
      "\tgrad:  1.0 2.0 tensor(24.9649)\n",
      "\tgrad:  2.0 4.0 tensor(18.5018)\n",
      "\tgrad:  3.0 6.0 tensor(0.6297)\n",
      "progress: 87 tensor(8.8726)\n",
      "\tgrad:  1.0 2.0 tensor(-1.3687)\n",
      "\tgrad:  2.0 4.0 tensor(-9.2527)\n",
      "\tgrad:  3.0 6.0 tensor(-25.3263)\n",
      "progress: 88 tensor(7.1767)\n",
      "\tgrad:  1.0 2.0 tensor(-26.6058)\n",
      "\tgrad:  2.0 4.0 tensor(-29.5950)\n",
      "\tgrad:  3.0 6.0 tensor(-30.9938)\n",
      "progress: 89 tensor(0.0543)\n",
      "\tgrad:  1.0 2.0 tensor(-30.5293)\n",
      "\tgrad:  2.0 4.0 tensor(-26.2291)\n",
      "\tgrad:  3.0 6.0 tensor(-11.8325)\n",
      "progress: 90 tensor(5.7573)\n",
      "\tgrad:  1.0 2.0 tensor(-9.9962)\n",
      "\tgrad:  2.0 4.0 tensor(-1.8514)\n",
      "\tgrad:  3.0 6.0 tensor(16.8077)\n",
      "progress: 91 tensor(9.6711)\n",
      "\tgrad:  1.0 2.0 tensor(18.5448)\n",
      "\tgrad:  2.0 4.0 tensor(24.0095)\n",
      "\tgrad:  3.0 6.0 tensor(31.9834)\n",
      "progress: 92 tensor(1.7662)\n",
      "\tgrad:  1.0 2.0 tensor(32.2297)\n",
      "\tgrad:  2.0 4.0 tensor(30.6366)\n",
      "\tgrad:  3.0 6.0 tensor(21.5376)\n",
      "progress: 93 tensor(2.2998)\n",
      "\tgrad:  1.0 2.0 tensor(20.0958)\n",
      "\tgrad:  2.0 4.0 tensor(12.7211)\n",
      "\tgrad:  3.0 6.0 tensor(-6.1617)\n",
      "progress: 94 tensor(9.9045)\n",
      "\tgrad:  1.0 2.0 tensor(-8.1366)\n",
      "\tgrad:  2.0 4.0 tensor(-15.3851)\n",
      "\tgrad:  3.0 6.0 tensor(-28.9250)\n",
      "progress: 95 tensor(5.0924)\n",
      "\tgrad:  1.0 2.0 tensor(-29.8509)\n",
      "\tgrad:  2.0 4.0 tensor(-31.1665)\n",
      "\tgrad:  3.0 6.0 tensor(-28.5168)\n",
      "progress: 96 tensor(0.1950)\n",
      "\tgrad:  1.0 2.0 tensor(-27.6520)\n",
      "\tgrad:  2.0 4.0 tensor(-21.9808)\n",
      "\tgrad:  3.0 6.0 tensor(-5.2641)\n",
      "progress: 97 tensor(7.7625)\n",
      "\tgrad:  1.0 2.0 tensor(-3.3014)\n",
      "\tgrad:  2.0 4.0 tensor(4.8135)\n",
      "\tgrad:  3.0 6.0 tensor(22.2055)\n",
      "progress: 98 tensor(8.4023)\n",
      "\tgrad:  1.0 2.0 tensor(23.6939)\n",
      "\tgrad:  2.0 4.0 tensor(27.7517)\n",
      "\tgrad:  3.0 6.0 tensor(31.8866)\n",
      "progress: 99 tensor(0.4749)\n",
      "predict (after training) 4 hours tensor([7.6434], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        \n",
    "    print(\"progress:\", epoch, l.data[0])\n",
    "    \n",
    "# After training\n",
    "print(\"predict (after training)\", \"4 hours\", forward(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
